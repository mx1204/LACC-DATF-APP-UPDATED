{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ“Š Workshop Attendance Analysis (Notebook Version)\n",
                "\n",
                "This notebook performs the attendance analysis. \n",
                "\n",
                "**Instructions:**\n",
                "1.  **Insert Data Paths**: Update the file paths in the code cell below.\n",
                "2.  **Run All Cells**: Execute the cells to load data and generate graphs.\n",
                "3.  **Check Attributes**: The \"Data Overview\" section will display all available columns (attributes) for your reference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import numpy as np\n",
                "\n",
                "# -----------------------------------------\n",
                "# 1ï¸âƒ£ Setup & Configuration\n",
                "# -----------------------------------------\n",
                "sns.set_style(\"whitegrid\")\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "# ğŸ‘‡ INSERT YOUR FILE PATHS HERE ğŸ‘‡\n",
                "attendance_file_paths = [\n",
                "    '/content/2023_2024_2025__Attendance_Report (1).xlsx',\n",
                "    # '/content/Another_File.csv', \n",
                "]\n",
                "taxonomy_file_path = '/content/Taxonomy.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -----------------------------------------\n",
                "# 2ï¸âƒ£ Load & Inspect Data (Interface)\n",
                "# -----------------------------------------\n",
                "def load_and_display_data():\n",
                "    # --- Load Attendance ---\n",
                "    df_list = []\n",
                "    for path in attendance_file_paths:\n",
                "        if os.path.exists(path):\n",
                "            try:\n",
                "                if path.lower().endswith('.csv'):\n",
                "                    df_temp = pd.read_csv(path)\n",
                "                else:\n",
                "                    df_temp = pd.read_excel(path)\n",
                "                df_list.append(df_temp)\n",
                "                print(f\"âœ… Loaded: {path}\")\n",
                "            except Exception as e:\n",
                "                print(f\"âŒ Error loading {path}: {e}\")\n",
                "        else:\n",
                "            print(f\"âš ï¸ File not found: {path}\")\n",
                "\n",
                "    if df_list:\n",
                "        df_att = pd.concat(df_list, ignore_index=True)\n",
                "    else:\n",
                "        print(\"âŒ No valid attendance data found.\")\n",
                "        return pd.DataFrame(), pd.DataFrame()\n",
                "\n",
                "    # --- Load Taxonomy ---\n",
                "    if os.path.exists(taxonomy_file_path):\n",
                "        try:\n",
                "            if taxonomy_file_path.lower().endswith('.csv'):\n",
                "                df_tax = pd.read_csv(taxonomy_file_path)\n",
                "            else:\n",
                "                df_tax = pd.read_excel(taxonomy_file_path)\n",
                "            print(f\"âœ… Loaded: {taxonomy_file_path}\")\n",
                "        except Exception as e:\n",
                "            print(f\"âŒ Error loading taxonomy: {e}\")\n",
                "            df_tax = pd.DataFrame()\n",
                "    else:\n",
                "        print(f\"âš ï¸ Taxonomy file not found: {taxonomy_file_path}\")\n",
                "        df_tax = pd.DataFrame()\n",
                "\n",
                "    return df_att, df_tax\n",
                "\n",
                "df, df_taxonomy = load_and_display_data()\n",
                "\n",
                "if not df.empty:\n",
                "    print(\"\\n\" + \"=\"*40)\n",
                "    print(\"ğŸ“‹ DATA INTERFACE: AVAILABLE ATTRIBUTES\")\n",
                "    print(\"=\"*40)\n",
                "    print(f\"Total Records: {len(df)}\")\n",
                "    print(\"\\n--- Attendance Data Columns ---\")\n",
                "    for col in df.columns:\n",
                "        print(f\" â€¢ {col}\")\n",
                "    \n",
                "    print(\"\\n--- Taxonomy Data Columns ---\")\n",
                "    if not df_taxonomy.empty:\n",
                "        for col in df_taxonomy.columns:\n",
                "            print(f\" â€¢ {col}\")\n",
                "    else:\n",
                "        print(\" (No Taxonomy Data Loaded)\")\n",
                "    print(\"=\"*40 + \"\\n\")\n",
                "else:\n",
                "    print(\"âŒ STOP: Please fix file paths above.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -----------------------------------------\n",
                "# 3ï¸âƒ£ Data Cleaning & Merging\n",
                "# -----------------------------------------\n",
                "if not df.empty and not df_taxonomy.empty:\n",
                "    # Clean Columns\n",
                "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('[^a-z0-9_]', '', regex=True)\n",
                "    \n",
                "    rename_map = {\n",
                "        'simid': 'student_id', \n",
                "        'university_program': 'university_program',\n",
                "        'attendance_status': 'attendance_status',\n",
                "        'event_name': 'event_name',\n",
                "        'attended_date': 'attended_date',\n",
                "        'attended_time': 'attended_time',\n",
                "        'registered_date': 'registered_date',\n",
                "        'citizenship': 'citizenship',\n",
                "        'nationality': 'nationality',\n",
                "        'expected_grad_term': 'expected_grad_term'\n",
                "    }\n",
                "    df = df.rename(columns=rename_map)\n",
                "\n",
                "    # Clean Event Names\n",
                "    if 'event_name' in df.columns:\n",
                "        df['event_name_clean'] = df['event_name'].str.replace(r'[\\(\\)]', '', regex=True).str.strip().str.lower()\n",
                "    \n",
                "    if 'Career Development Workshop Titles' in df_taxonomy.columns:\n",
                "        df_taxonomy['workshop_title_clean'] = df_taxonomy['Career Development Workshop Titles'].str.replace(r'[\\(\\)]', '', regex=True).str.strip().str.lower()\n",
                "\n",
                "    # Merge\n",
                "    df = df.merge(\n",
                "        df_taxonomy[['workshop_title_clean', 'Category', 'Sub-Category']], \n",
                "        left_on='event_name_clean', \n",
                "        right_on='workshop_title_clean', \n",
                "        how='left'\n",
                "    )\n",
                "\n",
                "    df['Category'] = df['Category'].fillna('Uncategorized')\n",
                "    df['Sub-Category'] = df['Sub-Category'].fillna('Uncategorized')\n",
                "    df['is_attended'] = df['attendance_status'].apply(lambda x: 1 if str(x).lower() == 'attended' else 0)\n",
                "    \n",
                "    # University\n",
                "    if 'university_program' not in df.columns:\n",
                "        possible_cols = [c for c in df.columns if 'university' in c or 'program' in c]\n",
                "        if possible_cols:\n",
                "            df['university_program'] = df[possible_cols[0]]\n",
                "        else:\n",
                "            df['university_program'] = 'Unknown'\n",
                "    \n",
                "    df['uni_category'] = df['university_program'].fillna('Unknown')\n",
                "    df_attended = df[df['is_attended'] == 1].copy()\n",
                "    \n",
                "    print(\"âœ… Data Merged and Cleaned.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Overall Attendance Overview\n",
                "Analyze total attendance per student (single vs. multi-run)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty:\n",
                "    student_counts = df_attended.groupby('student_id')['event_name'].count()\n",
                "    single_attendees = student_counts[student_counts == 1].count()\n",
                "    multi_attendees = student_counts[student_counts > 1].count()\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    plt.pie([single_attendees, multi_attendees], labels=['Single Workshop', 'Multiple Workshops'], \n",
                "            autopct='%1.1f%%', colors=['#66b3ff', '#ff9999'], startangle=90)\n",
                "    plt.title('Student Attendance: Single vs Multi-Run', fontsize=14, fontweight='bold')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Unique Participant Count\n",
                "Count total unique attendees across all workshops"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty:\n",
                "    unique_count = df_attended['student_id'].nunique()\n",
                "    print(f\"\\nğŸ† Total Unique Participants: {unique_count}\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Most Popular Days & Time Slots\n",
                "Identify days/times with highest attendance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty and 'attended_date' in df_attended.columns:\n",
                "    # Convert to datetime\n",
                "    df_attended['attended_date_dt'] = pd.to_datetime(df_attended['attended_date'], errors='coerce')\n",
                "    \n",
                "    # Day of Week\n",
                "    day_counts = df_attended['attended_date_dt'].dt.day_name().value_counts()\n",
                "    # Sort by normal week order\n",
                "    days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
                "    day_counts = day_counts.reindex(days_order).dropna()\n",
                "    \n",
                "    plt.figure(figsize=(10, 5))\n",
                "    sns.barplot(x=day_counts.index, y=day_counts.values, palette='viridis')\n",
                "    plt.title('Attendance by Day of Week', fontsize=14)\n",
                "    plt.ylabel('Attendees')\n",
                "    plt.show()\n",
                "\n",
                "if not df_attended.empty and 'attended_time' in df_attended.columns:\n",
                "    # Try to extract hour\n",
                "    # Assuming time format might vary, let's try to convert\n",
                "    # If it's a string like '14:00:00', pd.to_datetime works\n",
                "    try:\n",
                "        df_attended['hour'] = pd.to_datetime(df_attended['attended_time'].astype(str), format='%H:%M:%S', errors='coerce').dt.hour\n",
                "        # Fallback for other formats if needed\n",
                "        if df_attended['hour'].isnull().all():\n",
                "             df_attended['hour'] = pd.to_datetime(df_attended['attended_time'].astype(str), errors='coerce').dt.hour\n",
                "\n",
                "        hour_counts = df_attended['hour'].value_counts().sort_index()\n",
                "        \n",
                "        plt.figure(figsize=(10, 5))\n",
                "        sns.barplot(x=hour_counts.index, y=hour_counts.values, color='teal')\n",
                "        plt.title('Attendance by Hour of Day', fontsize=14)\n",
                "        plt.xlabel('Hour (24h)')\n",
                "        plt.ylabel('Attendees')\n",
                "        plt.show()\n",
                "    except Exception as e:\n",
                "        print(f\"Could not parse time: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Attendance by University\n",
                "Examine attendance distribution across universities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty:\n",
                "    uni_counts = df_attended['uni_category'].value_counts()\n",
                "    \n",
                "    plt.figure(figsize=(12, 6))\n",
                "    sns.barplot(y=uni_counts.index, x=uni_counts.values, palette='magma')\n",
                "    plt.title('Total Attendance by University Program', fontsize=14)\n",
                "    plt.xlabel('Count')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Workshop Attendance by University & Subcategory\n",
                "Evaluate attendance variations by workshop subcategory per university, and display top 10 workshops title in each category in horizontal stack bar grapgh in ascending order within the a bar graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_stacked_bar(df_data, title):\n",
                "    if df_data.empty:\n",
                "        return\n",
                "\n",
                "    # Pivot\n",
                "    df_pivot = df_data.pivot(index='event_name', columns='uni_category', values='is_attended').fillna(0)\n",
                "    \n",
                "    # Sort Rows (Total Attendance Ascending -> Largest at Bottom/Top depending on plot)\n",
                "    df_pivot['total'] = df_pivot.sum(axis=1)\n",
                "    df_pivot = df_pivot.sort_values(by='total', ascending=True) \n",
                "    df_pivot = df_pivot.drop(columns=['total'])\n",
                "\n",
                "    # Sort Columns (Largest Uni on Left)\n",
                "    uni_totals = df_pivot.sum(axis=0).sort_values(ascending=False)\n",
                "    df_pivot = df_pivot[uni_totals.index.tolist()]\n",
                "\n",
                "    # Plot\n",
                "    plt.figure(figsize=(16, max(6, len(df_pivot) * 0.6)))\n",
                "    all_universities = sorted(df_attended['uni_category'].unique())\n",
                "    color_palette = plt.cm.tab20.colors\n",
                "    university_colors = {uni: color_palette[i % len(color_palette)] for i, uni in enumerate(all_universities)}\n",
                "    colors = [university_colors.get(col, '#333333') for col in df_pivot.columns]\n",
                "    \n",
                "    ax = df_pivot.plot(kind='barh', stacked=True, color=colors, width=0.7, ax=plt.gca())\n",
                "    \n",
                "    plt.title(title, fontsize=16, weight='bold')\n",
                "    plt.xlabel('Total Attendance', fontsize=12)\n",
                "    plt.ylabel('Workshop Title', fontsize=12)\n",
                "    \n",
                "    # Numbers\n",
                "    max_val = df_pivot.sum(axis=1).max()\n",
                "    plt.xlim(0, max_val * 1.25)\n",
                "    for i, event in enumerate(df_pivot.index):\n",
                "        cumulative = 0\n",
                "        for col in df_pivot.columns:\n",
                "            val = df_pivot.loc[event, col]\n",
                "            if val > 0:\n",
                "                ax.text(cumulative + val/2, i, f'{int(val)}', \n",
                "                        ha='center', va='center', color='white', fontsize=9, fontweight='bold')\n",
                "                cumulative += val\n",
                "        ax.text(cumulative + max_val*0.01, i, f'Total: {int(cumulative)}', \n",
                "                ha='left', va='center', color='black', fontweight='bold')\n",
                "\n",
                "    plt.legend(title='University Program', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "if not df_attended.empty:\n",
                "    categories = df_attended['Category'].unique()\n",
                "    for cat in categories:\n",
                "        sub_cats = df_attended[df_attended['Category'] == cat]['Sub-Category'].unique()\n",
                "        for sub in sub_cats:\n",
                "            df_sub = df_attended[(df_attended['Category'] == cat) & (df_attended['Sub-Category'] == sub)]\n",
                "            df_agg = df_sub.groupby(['event_name', 'uni_category'])['is_attended'].sum().reset_index()\n",
                "            event_totals = df_agg.groupby('event_name')['is_attended'].sum().reset_index()\n",
                "            top_10_events = event_totals.sort_values('is_attended', ascending=False).head(10)['event_name'].tolist()\n",
                "            df_plot = df_agg[df_agg['event_name'].isin(top_10_events)]\n",
                "            \n",
                "            plot_stacked_bar(df_plot, f'Top 10 Workshops: {cat} - {sub}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Attendance by Student Type (Local vs. International)\n",
                "Compare attendance trends"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty and ('citizenship' in df_attended.columns or 'nationality' in df_attended.columns):\n",
                "    # Determine Local vs International\n",
                "    # Priority: Citizenship -> Nationality\n",
                "    col_to_use = 'citizenship' if 'citizenship' in df_attended.columns else 'nationality'\n",
                "    \n",
                "    def get_student_type(val):\n",
                "        val_str = str(val).lower()\n",
                "        if 'singapore' in val_str or 'pr' in val_str or 'permanent resident' in val_str:\n",
                "            return 'Local'\n",
                "        return 'International'\n",
                "\n",
                "    df_attended['student_type'] = df_attended[col_to_use].apply(get_student_type)\n",
                "    \n",
                "    type_counts = df_attended['student_type'].value_counts()\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', colors=['#ffcc99', '#99ff99'], startangle=90)\n",
                "    plt.title(f'Attendance by Student Type (Based on {col_to_use})', fontsize=14, fontweight='bold')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Attendance by Expected Graduation Period\n",
                "Assess patterns based on graduation year"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty and 'expected_grad_term' in df_attended.columns:\n",
                "    grad_counts = df_attended['expected_grad_term'].value_counts().sort_index()\n",
                "    \n",
                "    plt.figure(figsize=(12, 6))\n",
                "    sns.barplot(x=grad_counts.index, y=grad_counts.values, palette='coolwarm')\n",
                "    plt.title('Attendance by Expected Graduation Term', fontsize=14)\n",
                "    plt.xticks(rotation=45)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Attendance Attribution Based on Registration Timing\n",
                "Analyze early vs. late registration and actual attendance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_attended.empty and 'registered_date' in df_attended.columns and 'attended_date' in df_attended.columns:\n",
                "    df_attended['reg_dt'] = pd.to_datetime(df_attended['registered_date'], errors='coerce')\n",
                "    df_attended['att_dt'] = pd.to_datetime(df_attended['attended_date'], errors='coerce')\n",
                "    \n",
                "    # Calculate days in advance\n",
                "    df_attended['days_advance'] = (df_attended['att_dt'] - df_attended['reg_dt']).dt.days\n",
                "    \n",
                "    def categorize_registration(days):\n",
                "        if pd.isna(days):\n",
                "            return 'Unknown'\n",
                "        if days >= 14:\n",
                "            return 'Early Bird (>2 weeks)'\n",
                "        elif days >= 3:\n",
                "            return 'Standard (3-14 days)'\n",
                "        else:\n",
                "            return 'Last Minute (<3 days)'\n",
                "\n",
                "    df_attended['reg_category'] = df_attended['days_advance'].apply(categorize_registration)\n",
                "    \n",
                "    reg_counts = df_attended['reg_category'].value_counts()\n",
                "    # Sort order\n",
                "    order = ['Early Bird (>2 weeks)', 'Standard (3-14 days)', 'Last Minute (<3 days)', 'Unknown']\n",
                "    reg_counts = reg_counts.reindex(order).dropna()\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.barplot(x=reg_counts.index, y=reg_counts.values, palette='Blues_d')\n",
                "    plt.title('Attendance Attribution by Registration Timing', fontsize=14)\n",
                "    plt.ylabel('Attendees')\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}